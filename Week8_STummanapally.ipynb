{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd1c587",
   "metadata": {},
   "source": [
    "# Exercise 9.1 \n",
    "As sample size increases, the power of a hypothesis test increases, which means it is more likely to be positive if the effect is real. Conversely, as sample size decreases, the test is less likely to be positive even if the effect is real.\n",
    "To investigate this behavior, run the tests in this chapter with different sub- sets of the NSFG data. You can use thinkstats2.SampleRows to select a random subset of the rows in a DataFrame.\n",
    "What happens to the p-values of these tests as sample size decreases? What is the smallest sample size that yields a positive test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88028e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\ttest1\ttest2\ttest3\ttest4\n",
      "9148\t0.16\t0.00\t0.00\t0.00\n",
      "4574\t0.10\t0.01\t0.00\t0.00\n",
      "2287\t0.25\t0.06\t0.00\t0.00\n",
      "1143\t0.24\t0.03\t0.39\t0.03\n",
      "571\t0.81\t0.00\t0.04\t0.04\n",
      "285\t0.57\t0.41\t0.48\t0.83\n",
      "142\t0.45\t0.08\t0.60\t0.04\n",
      "71\t1.00\t0.81\t0.38\t0.69\n"
     ]
    }
   ],
   "source": [
    "import nsfg\n",
    "import hypothesis\n",
    "import thinkstats2\n",
    "\n",
    "def RunTests(live, iters=1000):\n",
    "    \"\"\"function to run the tests from Chapter 9 with a subset of the data.\"\"\"\n",
    "    \n",
    "    n = len(live)\n",
    "    firsts = live[live.birthord == 1]\n",
    "    others = live[live.birthord != 1]\n",
    "\n",
    "    # test1: difference in mean pregnancy length.\n",
    "    data1 = firsts.prglngth.values, others.prglngth.values\n",
    "    ht = hypothesis.DiffMeansPermute(data1)\n",
    "    p1 = ht.PValue(iters)\n",
    "    \n",
    "    # test2: difference in mean birth weight.\n",
    "    data2 = (firsts.totalwgt_lb.dropna().values,\n",
    "            others.totalwgt_lb.dropna().values)\n",
    "    ht = hypothesis.DiffMeansPermute(data2)\n",
    "    p2 = ht.PValue(iters)\n",
    "\n",
    "    # test3: correlation of mother's age and birth weight.\n",
    "    live2 = live.dropna(subset=['agepreg', 'totalwgt_lb'])\n",
    "    data3 = live2.agepreg.values, live2.totalwgt_lb.values\n",
    "    ht = hypothesis.CorrelationPermute(data3)\n",
    "    p3 = ht.PValue(iters)\n",
    "\n",
    "    # test4: chi-square test of pregnancy length.\n",
    "    ht = hypothesis.PregLengthTest(data1)\n",
    "    p4 = ht.PValue(iters)\n",
    "    \n",
    "    print('%d\\t%0.2f\\t%0.2f\\t%0.2f\\t%0.2f' % (n, p1, p2, p3, p4))\n",
    "\n",
    "\n",
    "def main():\n",
    "    thinkstats2.RandomSeed(18)\n",
    "    \n",
    "    preg = nsfg.ReadFemPreg()\n",
    "    live = preg[preg.outcome == 1]\n",
    "    n = len(live)\n",
    "    \n",
    "    print('n\\ttest1\\ttest2\\ttest3\\ttest4')\n",
    "    for _ in range(8):\n",
    "        sample = thinkstats2.SampleRows(live, n)\n",
    "        RunTests(sample)\n",
    "        n //= 2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d154772",
   "metadata": {},
   "source": [
    "My observations:\n",
    "\n",
    "Details of the tests: \n",
    "test1: difference in mean pregnancy length\n",
    "test2: difference in mean birth weight\n",
    "test3: correlation of mother's age and birth weight\n",
    "test4: chi-square test of pregnancy length\n",
    "\n",
    "\n",
    "Except for the test1 - on pregnancy length, the P-value for all the tests is very low / almost negligble i.e. <0.05 for larger samples. This means the null hypothesis is false with the exception of test1. Smallest sample size of 71 seems to be yielding positive test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc902d7",
   "metadata": {},
   "source": [
    "# Exercise 10.1 \n",
    "Using the data from the BRFSS, compute the linear least squares fit for log(weight) versus height. How would you best present the estimated parameters for a model like this where one of the variables is log- transformed? If you were trying to guess someoneâ€™s weight, how much would it help to know their height?\n",
    "Like the NSFG, the BRFSS oversamples some groups and provides a sampling weight for each respondent. In the BRFSS data, the variable name for these weights is finalwt. Use resampling, with and without weights, to estimate the mean height of respondents in the BRFSS, the standard error of the mean, and a 90% confidence interval. How much does correct weighting affect the estimates?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brfss\n",
    "from thinkstats2 import Mean, MeanVar, Var, Std, Cov\n",
    "import thinkplot\n",
    "import numpy as np\n",
    "\n",
    "def LeastSquares(xs, ys):\n",
    "    meanx, varx = MeanVar(xs)\n",
    "    meany = Mean(ys)\n",
    "\n",
    "    slope = Cov(xs, ys, meanx, meany) / varx\n",
    "    inter = meany - slope * meanx\n",
    "\n",
    "    return inter, slope\n",
    "\n",
    "df = brfss.ReadBrfss(nrows=None)\n",
    "df = df.dropna(subset=['htm3', 'wtkg2'])\n",
    "heights, weights = df.htm3, df.wtkg2\n",
    "log_weights = np.log10(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the linear squares fit for log(weight) vs height:\n",
    "inter, slope = thinkstats2.LeastSquares(heights, log_weights)\n",
    "inter, slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd18f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the data and showing the fitted line with x-axis as height, y-axis as log wgt\n",
    "thinkplot.Scatter(heights, log_weights, alpha=0.02, s=2)\n",
    "fxs, fys = thinkstats2.FitLine(heights, inter, slope)\n",
    "thinkplot.Plot(fxs, fys, color='red')\n",
    "thinkplot.Config(xlabel='Height (cm)', ylabel='log10 weight (kg)', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same plot but applying the inverse transform to show weights on a linear (not log) scale.\n",
    "thinkplot.Scatter(heights, weights, alpha=0.02, s=2)\n",
    "fxs, fys = thinkstats2.FitLine(heights, inter, slope)\n",
    "thinkplot.Plot(fxs, 10**fys, color='red')\n",
    "thinkplot.Config(xlabel='Height (cm)', ylabel='Weight (kg)', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079e6f3",
   "metadata": {},
   "source": [
    "Plot percentiles of the residuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a59c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate residuals\n",
    "res = thinkstats2.Residuals(heights, log_weights, inter, slope)\n",
    "df['residual'] = res\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(130, 210, 5)  \n",
    "indices = np.digitize(df.htm3, bins)\n",
    "groups = df.groupby(indices)\n",
    "\n",
    "means = [group.htm3.mean() for i, group in groups][1:-1]\n",
    "cdfs = [thinkstats2.Cdf(group.residual) for i, group in groups][1:-1]\n",
    "\n",
    "thinkplot.PrePlot(3)\n",
    "for percent in [75, 50, 25]:\n",
    "    ys = [cdf.Percentile(percent) for cdf in cdfs]\n",
    "    label = '%dth' % percent\n",
    "    thinkplot.Plot(means, ys, label=label)\n",
    "    \n",
    "thinkplot.Config(xlabel='height (cm)', ylabel='residual weight (kg)', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723cd695",
   "metadata": {},
   "source": [
    "The lines are flat over most of the range, indicating that the relationship is linear.\n",
    "The lines are mostly parallel, indicating that the variance of the residuals is the same over the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8418429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing correlation.\n",
    "corr = thinkstats2.Corr(heights, log_weights)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbae798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing coefficient of determination.\n",
    "r2 = thinkstats2.CoefDetermination(log_weights, res)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming that ð‘…2=ðœŒ2.\n",
    "corr**2 - r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Std(ys), which is the RMSE of predictions that don't use height.\n",
    "std_ys = thinkstats2.Std(log_weights) #get std dv of residuals\n",
    "std_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Std(res), the RMSE of predictions that do use height.\n",
    "std_res = thinkstats2.Std(res)\n",
    "std_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44acf4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# height information that reduce RMSE.\n",
    "1 - std_res / std_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7203ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using resampling to compute sampling distributions for inter and slope.\n",
    "t = [] # creating an empty list\n",
    "for _ in range(100):\n",
    "    sample = thinkstats2.ResampleRows(df)\n",
    "    estimates = thinkstats2.LeastSquares(sample.htm3, np.log10(sample.wtkg2)) #get intercept & slope\n",
    "    t.append(estimates) # add result to the list\n",
    "\n",
    "inters, slopes = zip(*t) # unzip the results\n",
    "print(inters)\n",
    "print(slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72718a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the sampling distribution of slope.\n",
    "cdf = thinkstats2.Cdf(slopes) # calculating the cdf\n",
    "thinkplot.Cdf(cdf) #plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04049290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the p-value of the slope.\n",
    "pvalue = cdf[0]\n",
    "print(\"p-value is\", pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the 90% confidence interval of slope.\n",
    "ci = cdf.Percentile(5), cdf.Percentile(95) # get 90% confidence interval \n",
    "ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c76f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the mean of the sampling distribution.\n",
    "mean = thinkstats2.Mean(slopes) # calculate mean slopes\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the standard deviation of the sampling distribution, which is the standard error.\n",
    "stderr = thinkstats2.Std(slopes) # get std error\n",
    "stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Summarize(estimates, actual=None):\n",
    "    mean = Mean(estimates)\n",
    "    stderr = Std(estimates, mu=actual)\n",
    "    cdf = thinkstats2.Cdf(estimates)\n",
    "    ci = cdf.ConfidenceInterval(90)\n",
    "    print('mean, SE, CI', mean, stderr, ci)  \n",
    "    \n",
    "def ResampleRowsWeighted(df, column='finalwgt'):\n",
    "    weights = df[column]\n",
    "    cdf = thinkstats2.Cdf(dict(weights))\n",
    "    indices = cdf.Sample(len(weights))\n",
    "    sample = df.loc[indices]\n",
    "    return sample    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f1b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling rows without weights, compute mean height, and summarize results.\n",
    "\n",
    "estimates_unweighted = [thinkstats2.ResampleRows(df).htm3.mean() for _ in range(100)]\n",
    "Summarize(estimates_unweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling rows with weights.\n",
    "\n",
    "estimates_weighted = [ResampleRowsWeighted(df, 'finalwt').htm3.mean() for _ in range(100)]\n",
    "Summarize(estimates_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e329b59d",
   "metadata": {},
   "source": [
    "The estimated mean height is almost 2 cm taller if we take into account the sampling weights, and this difference is much bigger than the sampling error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
